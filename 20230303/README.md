# 규제
* 머신러닝 모델이 훈련세트를 너무 과도하게 학습하지 못하도록 훼방하는것을 말함
* 즉 모델이 훈련세트에 과대적합되지 않도록 도와줌
* ex)선형회귀{특성에 곱해지는 계수(기울기)의 크기를 작게만드는것}
### ridge
* 계수를 제곱한 값을 기준으로 규제를 적용
### lasso
* 계수의 절댓값을 기준으로 규제를 적용


* ConvergenceWarning
* 라쏘모델은 최적의 계수를 찾기 위해 반복적인 계산수행->만약 지정한 반복횟수가 부족할때 해당 Warning발생


# 로지스틱회귀(Logistic Regression)
* 로지스틱회귀는 사건이 발생할 가능성을 예측하는데 사용하는 모델임
* 주로 특정환경이 주어졌을때, 사건이 일어나는지, 안일어나는지에 대해 다룸
### 시그모이드 함수(Sigmoid함수)
![image](https://user-images.githubusercontent.com/126637081/229262309-055d1622-4ab5-4a5d-b857-8e89f21c4af9.png)
![image](https://user-images.githubusercontent.com/126637081/229262341-ceda3e11-0bca-4a38-b157-2aa7e3351c56.png)
* x가 0보다 크면 y는 0.5기준으로 긍정
* x가 0보다 작으면 y는 0.5기준으로 부정
### 시그모이드 함수를 사용하는 이유
* 선형으로 나타내었을때 문제점이 발생하기 때문
![image](https://user-images.githubusercontent.com/126637081/229262409-44801fe4-d081-414d-a61f-c071a69f682c.png)
* 위의 선형형태의 그래프를 보면 x값이 5보다 크면 사건이 발생하고, 5보다 작으면 발생하지 않는다고 말하고있다.
* 빨간 동그라미 친 x가 9인데 사건이 발생하지 않는경우가 들어가서 5를 기준으로 예측했던 모델에 문제발생
* 새로운 값의 추가가 기존 분류 모델에 큰 영향을 미침
### 선형이 아닌 다중분류에서의 이용
### 시그모이드 함수가 아닌 소프트맥스(softmax)함수 이용'\
* 소프트 맥스 함수는 분류해야하는 클래스의 총 개수를 k라고 할때 k차원의 벡터를 입력받앙 각 클래스에 대한 확률을 추정함
* 소프트맥스 회귀는 선택지의 개수만큼의 차원을 가지는 벡터를 만들고, 해당 벡터가 벡터의 모든 원소의 합이 1이 되도록 원소들의 값을 변환시키는 어떤 함수를 지나게 만들어야 함
![image](https://user-images.githubusercontent.com/126637081/229262680-5e89fd3f-585c-419c-b4bc-a6ab62b76411.png)
![image](https://user-images.githubusercontent.com/126637081/229262710-4cf3cb23-d021-4438-a059-f6b950ce1d7b.png)
